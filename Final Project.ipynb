{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats as stats\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Superclass (Done?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Classifier fitting function\n",
    "            X_train: the features\n",
    "            Y_train: the labels\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Classifier prediction function; to be filled in individually for each classifier\n",
    "        If the subclass has no prediction function, raise an error\n",
    "        \"\"\"\n",
    "        raise RuntimeError(\"This classifier does not have a prediction function\")\n",
    "\n",
    "    def score(self, X_pred, Y_pred):\n",
    "        \"\"\"\n",
    "        Classifier score function.\n",
    "            X_pred: Feature vectors in training set\n",
    "            Y_pred: Corresponding labels for X_pred\n",
    "        \"\"\"\n",
    "        return np.mean(np.equal(self.predict(X_pred), Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 1 - K-Nearest Neighbors (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNclassifier(Classifier):\n",
    "    def __init__(self, k=2):\n",
    "        self.k = k\n",
    "        \n",
    "    def predict(self, X,sparse=True):\n",
    "        \"\"\"\n",
    "        k-NN prediction function. Adapted from code I had previously written in HW6\n",
    "            X_pred: Feature vectors in training set.\n",
    "        Return the predicted labels for X_pred. Shape: (len(X_pred), )\n",
    "        \"\"\"\n",
    "        Y_pred = []\n",
    "        \n",
    "        #calculate distances\n",
    "        if not sparse:\n",
    "            distances = np.linalg.norm(self.X_train[:, np.newaxis] - X, axis = 2)\n",
    "        if sparse:\n",
    "            \n",
    "        #append labels to each distance\n",
    "        #labels = np.tile(self.Y_train, (distances.shape[1],1)).T\n",
    "        #labeled_distances = np.stack((distances,labels), axis =2)\n",
    "    \n",
    "        #Sort Array based on Distances and find the k closest\n",
    "        sort_indexes = np.argsort(distances,axis = 0)[0:self.k].T\n",
    "        for indeces in sort_indexes:\n",
    "            y_vals = []\n",
    "            for index in indeces:\n",
    "                y_vals.append(self.Y_train[index])\n",
    "            Y_pred.append(stats.mode(y_vals)[0][0])\n",
    "        \n",
    "        return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier(Classifier):\n",
    "    def __init__(self, depth, trees):\n",
    "        self.depth = depth\n",
    "        self.trees = trees\n",
    "#    def predict(self, X_test):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 3 - Support Vector Machine (Done w/ linear; still need rbf implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier(Classifier):\n",
    "    def __init__(self, kernel = 'linear',lmda = 5):\n",
    "        valid_kernels = ['linear', 'rbf']\n",
    "        if kernel not in valid_kernels:\n",
    "            raise ValueError('bad kernel')\n",
    "        self.kernels = kernel\n",
    "        self.lmda = lmda\n",
    "            \n",
    "    def fit(self, X_train, Y_train, eta = 0.00005,threshold = 0.00000001, itr = 1000, filename = \"svm_test.txt\"):\n",
    "        \"\"\"\n",
    "        SVM fitting function. Computes the optimal value of theta and stores it as a parameter of the object\n",
    "            X_train: Feature vectors in training set.\n",
    "            Y_train: Labels in training set.\n",
    "            eta: learning rate. Initially set to be 0.05\n",
    "            threshold: point at which the new theta and old theta differ to stop stop iteration\n",
    "            itr: maximum number of iterations\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        f= open(filename,\"w+\")\n",
    "        \n",
    "        #initialize theta* as a random matrix\n",
    "        self.theta_star = np.random.random(X_train.shape[1])\n",
    "        \n",
    "        def h(x,y,theta):\n",
    "            \"\"\"\n",
    "            helper function to calculate the above h(x_i) term in the gradient\n",
    "                x: the i-th vector\n",
    "                y: the label of x\n",
    "                theta: paramter to be optimized\n",
    "            \"\"\"\n",
    "            #if y*x.dot(theta) >= 1:\n",
    "            #    return 0\n",
    "            #else:\n",
    "            #    return -y*x\n",
    "            \n",
    "            # Create a Sparse Diagonal Matrix whose entries correspond to 1 if y*<x,theta> >=1 and 0 else\n",
    "            # That sparse matrix is then used to \"zero out\" any vectors that have low loss value\n",
    "            # That new matrix is then summed over columnwise\n",
    "            S = (((np.sign(y*x.dot(theta)-1)-1)/-2))\n",
    "            S = sp.sparse.diags(S)\n",
    "            S = -S*y\n",
    "            return np.sum(S.dot(x),axis=0)\n",
    "        \n",
    "        #def SVM_grad(X,Y,theta):\n",
    "        #    \"\"\"\n",
    "        #    helper function to calculate the gradient of the SVM loss function with respect to theta\n",
    "        #        X: collection of vectors\n",
    "        #        Y: collection of labels\n",
    "        #        theta: parameter to be optimized\n",
    "        #    \"\"\"\n",
    "        #    return 2*theta + self.lmda*h(X,Y,theta)\n",
    "        \n",
    "        \n",
    "        # Lambda function to \n",
    "        gradient = lambda X,Y,theta: 2*theta + self.lmda*h(X,Y,theta)\n",
    "        \n",
    "        for i in range(itr):\n",
    "#            new_theta = self.theta_star - eta*SVM_grad(self.X_train, self.Y_train, self.theta_star)\n",
    "            new_theta = self.theta_star - eta*gradient(self.X_train, self.Y_train, self.theta_star)\n",
    "            if np.linalg.norm(new_theta - self.theta_star, ord = 1) < threshold:\n",
    "                print('broke at iteration ' + str(i))\n",
    "                break\n",
    "            self.theta_star = new_theta\n",
    "            #normalizing theta to prevent overflow\n",
    "            #self.theta_star = self.theta_star/np.linalg.norm(self.theta_star)\n",
    "        toc = time.time()\n",
    "        f.write(\"lambda = {}\\neta = {}\\nw = {}\\ntraining accuracy is = {}\\nApproximate time to run was : {}\\nSize of data was {}\".format(self.lmda, eta, self.theta_star,self.score(self.X_train, self.Y_train), (toc-tic), self.X_train.shape))\n",
    "        \n",
    "    def predict(self, X_Val):\n",
    "        \"\"\"\n",
    "        SVM prediction function.\n",
    "            X_Val: Feature vectors in training set.\n",
    "        Return the predicted labels for X_pred. Shape: (len(X_Val), )\n",
    "        \"\"\"\n",
    "        Y_pred = []\n",
    "        \n",
    "        for x in X_Val:\n",
    "            pred = 2*int((x.dot(self.theta_star)).astype(np.float64) > 0)-1\n",
    "            Y_pred.append(pred)\n",
    "            \n",
    "        return np.array(Y_pred)\n",
    "    \n",
    "    def normalize_theta(self):\n",
    "        self.theta_star = self.theta_star/np.linalg.norm(self.theta_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 4 - Linear Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-2104fa6adcb4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-2104fa6adcb4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Boosting(Classifier):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 5 - Single-Layer Perceptron (Some issues still)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(Classifier):\n",
    "    def __init__(self, epochs = 2):\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, X_train, Y_train, filename = 'perceptron_test.txt'):\n",
    "        \n",
    "#        f= open(filename,\"w+\")\n",
    "        tic = time.time()\n",
    "        self.X_train = X_train#np.c_[np.ones(X_train.shape[0]),X_train]\n",
    "        self.Y_train = Y_train\n",
    "        self.w = np.zeros(self.X_train.shape[1])\n",
    "#        tuned = False\n",
    "#        max_length = self.X_train.shape[0]**2\n",
    "#        i = 0\n",
    "        \n",
    "#        while not tuned and i < max_length:\n",
    "        for i in range(self.epochs):\n",
    "            for x,y in zip(self.X_train, self.Y_train):\n",
    "                if np.sign(x.dot(self.w)) != y:\n",
    "                    new_w = self.w + 2*y*x\n",
    "                    self.w = new_w\n",
    "        toc = time.time()\n",
    "#        f.write(\"epochs = {}\\nw = {}\\ntraining accuracy is = {}\\nApproximate time to run was : {}\\nSize of data was {}\".format(self.epochs, self.w,self.score(self.X_train, self.Y_train), (toc-tic), self.X_train.shape))\n",
    "        \n",
    "\n",
    "    def predict(self, X_val):\n",
    "        Y_pred = []\n",
    "        \n",
    "        for x in X_val:\n",
    "            pred = 2*int((x.dot(self.w)).astype(np.float64) > 0)-1\n",
    "            Y_pred.append(pred)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 6 - Logistic Regression (maybe not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionClassifier(Classifier):\n",
    "    def fit(X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        self.w = np.zeros(self.X_train.shape[1])\n",
    "        self.b = 0\n",
    "        \n",
    "        def logistic_prob(x,y,W,b):\n",
    "            return 1/(1+np.exp( (-2*y+1)*(W.T.dot(x)+b) ))\n",
    "        \n",
    "        def logistic_loss_gradients(X,Y,W,b):\n",
    "    \n",
    "            P = logistic_prob(X.T, Y.T, w, b).T\n",
    "            #w_grad = \n",
    "            for x,y in zip(X,Y):\n",
    "                p = logistic_prob(x,y,w,b).T\n",
    "                \n",
    "            #w_grad = X.dot(Y-P.dot(X))\n",
    "            #b_grad = Y-P.dot(X)\n",
    "    \n",
    "            return w_grad.T, np.float64(b_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning Functions (CV and GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(X, Y, Classifier, fold = 3):\n",
    "    #split data into k partitions\n",
    "    Y_fold = np.array_split(Y,fold)\n",
    "    X_fold = np.array_split(X,fold)\n",
    "    \n",
    "    #defining accuracies before going into loop\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    for i in range(fold):\n",
    "        \n",
    "        #taking one value out for validation\n",
    "        indeces = list(np.linspace(0, fold-1,fold).astype(int))\n",
    "        indeces.remove(i)\n",
    "        X_val = X_fold[i]\n",
    "        Y_val = Y_fold[i]\n",
    "        \n",
    "        X_train = np.vstack((x for j,x in enumerate(X_fold) if j!=i))\n",
    "        Y_train = np.hstack((y for j,y in enumerate(Y_fold) if j!=i))\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)\n",
    "        train_acc.append(classifier.score(X_train, Y_train))\n",
    "        val_acc.append(classifier.score(X_val, Y_val))\n",
    "    \n",
    "    return np.mean(train_acc), np.mean(val_acc)\n",
    "    \n",
    "\n",
    "def GridSearch(X,Y, Classifier, param_list, folds = 3):\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "#    np.random.seed(0)\n",
    "#    np.random.shuffle(Data)\n",
    "#    X = Data.T[0:len(Data.T)-2].T\n",
    "#    Y = Data.T[len(Data.T)-1]\n",
    "    for param in param_list:\n",
    "        a,b = CrossValidation(X,Y, Classifier, par = param, fold = folds)\n",
    "        train_accs.append(a)\n",
    "        val_accs.append(b)\n",
    "    return np.matrix(train_accs).T, np.matrix(val_accs).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1 - Dota 2 data from UCI ML repo\n",
    "Dota_Train = np.genfromtxt('./dota2Dataset/dota2Train.csv', delimiter=',')\n",
    "Dota_Test = np.genfromtxt('./dota2Dataset/dota2Test.csv', delimiter=',')\n",
    "\n",
    "Dota = np.vstack((Dota_Train,Dota_Test))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(Dota)\n",
    "Dota_X = Dota.T[4:].T\n",
    "Dota_Y = Dota.T[0]\n",
    "Ones_Dota_X = np.c_[ np.ones(Dota_X.shape[0]), Dota_X ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparse_X1 = sp.sparse.csr_matrix(Ones_Dota_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparse_X1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2 - Skin data from UCI ML repo\n",
    "Skin = np.loadtxt('Skin_NonSkin.txt')\n",
    "# Mapping labels from {1,2} (Skin, Not Skin) to {1,-1} (Skin, Not Skin)\n",
    "Skin[:,3] = -2*Skin[:,3]+3\n",
    "\n",
    "np.random.seed(4)\n",
    "np.random.shuffle(Skin)\n",
    "Skin_X = Skin.T[0:-1].T\n",
    "Skin_Y = Skin.T[-1]\n",
    "Ones_Skin_X = np.c_[ np.ones(Skin_X.shape[0]), Skin_X ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2910\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2911\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-d29cf500d2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparse_X1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDota_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#svm2.predict(Ones_Dota_X[0:n])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-163bfa35c72a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, eta, threshold, itr, filename)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#            new_theta = self.theta_star - eta*SVM_grad(self.X_train, self.Y_train, self.theta_star)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mnew_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_star\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_theta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-163bfa35c72a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(X, Y, theta)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Lambda function to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-163bfa35c72a>\u001b[0m in \u001b[0;36mh\u001b[0;34m(x, y, theta)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_mul_scalar\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/bsr.py\u001b[0m in \u001b[0;36m_with_data\u001b[0;34m(self, data, copy)\u001b[0m\n\u001b[1;32m    665\u001b[0m             return self.__class__((data,self.indices.copy(),self.indptr.copy()),\n\u001b[0;32m--> 666\u001b[0;31m                                    shape=self.shape,dtype=data.dtype)\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/bsr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy, blocksize)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm2 = SVMClassifier(lmda=5)\n",
    "svm2.fit(Ones_Dota_X,Dota_Y)\n",
    "#svm2.predict(Ones_Dota_X[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  0., -1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 2.,  0., -1., ...,  1.,  0.,  0.],\n",
       "       [ 2.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dota[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1, -1,  1,  1, -1,  1, -1,\n",
       "        1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1, -1,  1,  1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,\n",
       "        1, -1,  1, -1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1, -1,  1,  1, -1,\n",
       "        1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "       -1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
       "       -1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
       "        1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,\n",
       "        1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1, -1,  1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1, -1,\n",
       "       -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,\n",
       "       -1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1,  1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        1, -1,  1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1,  1, -1,\n",
       "        1,  1, -1, -1,  1,  1, -1,  1, -1, -1,  1,  1, -1,  1, -1,  1,  1,\n",
       "       -1, -1, -1,  1, -1, -1,  1,  1, -1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 400\n",
    "\n",
    "svm2 = SVMClassifier(lmda=5)\n",
    "svm2.fit(Ones_Dota_X[0:n],Dota_Y[0:n])\n",
    "svm2.predict(Ones_Dota_X[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(Ones_Dota_X[0:n],Dota_Y[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5077941417694092 seconds\n",
      " score = 0.8459705293054269\n",
      "\n",
      "2.0896408557891846 seconds\n",
      " score = 0.766458415797141\n",
      "\n",
      "3.5442380905151367 seconds\n",
      " score = 0.8937879758586778\n",
      "\n",
      "6.346112966537476 seconds\n",
      " score = 0.934215305010671\n",
      "\n",
      "11.776028871536255 seconds\n",
      " score = 0.9237973206233652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_list = [1, 2, 4, 8, 16]\n",
    "for i in i_list:\n",
    "    tic = time.time()\n",
    "    ptron = Perceptron(epochs = i)\n",
    "    ptron.fit(Ones_Skin_X,Skin_Y)\n",
    "    toc = time.time()\n",
    "    print(\"{} seconds\\n score = {}\\n\".format((toc-tic), ptron.score(Ones_Skin_X,Skin_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.005782127380371 seconds\n",
      " score = 0.20753947040892526\n",
      "\n",
      "8.406216859817505 seconds\n",
      " score = 0.20753947040892526\n",
      "\n",
      "8.386011123657227 seconds\n",
      " score = 0.20753947040892526\n",
      "\n",
      "8.387519836425781 seconds\n",
      " score = 0.20753947040892526\n",
      "\n",
      "10.513423919677734 seconds\n",
      " score = 0.20753947040892526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lmda_list = [1,2,3,4,5]\n",
    "for i in lmda_list:\n",
    "    tic = time.time()\n",
    "    svm = SVMClassifier(lmda = i)\n",
    "    svm.fit(Ones_Skin_X,Skin_Y)\n",
    "    toc = time.time()\n",
    "    print(\"{} seconds\\n score = {}\\n\".format((toc-tic), svm.score(Ones_Skin_X,Skin_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 200., 198., 164.],\n",
       "       [  1., 129., 166., 218.],\n",
       "       [  1., 146., 148.,  96.],\n",
       "       ...,\n",
       "       [  1., 200., 198., 158.],\n",
       "       [  1.,  41.,  71.,  52.],\n",
       "       [  1., 195., 193., 159.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ones_Skin_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(Ones_Skin_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20753947040892526"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((Skin_Y+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1758.85274567, 1758.97873174, 1758.66708517, 1758.7590157 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35030402, 0.79162491, 0.43092038, 1.09024388, 0.64839485,\n",
       "       0.34335682, 0.3444459 , 0.69249426, 0.51271492, 1.21674895,\n",
       "       0.71747285, 0.85707379, 1.04883894, 1.06980197, 0.68727413,\n",
       "       0.66722918, 0.82575396, 0.56230516, 0.87998898, 0.64982577,\n",
       "       1.10265711, 0.31615285, 0.89484125, 0.57635154, 0.64275319,\n",
       "       1.15655842, 0.31882848, 0.75205156, 0.47448649, 1.04267733,\n",
       "       0.39247871, 0.81151419, 1.03865719, 0.42016916, 0.33655875,\n",
       "       0.63233394, 1.06876154, 1.08036204, 0.84611903, 0.89617121,\n",
       "       0.45044837, 0.9417726 , 1.11038354, 0.69868263, 0.92626105,\n",
       "       1.12542344, 1.0915871 , 0.44556315, 1.06767705, 1.05734364,\n",
       "       1.02612722, 0.84332004, 0.40187903, 0.50500369, 0.39342636,\n",
       "       0.52480518, 1.16714717, 1.21976824, 0.67599529, 0.7317163 ,\n",
       "       0.51556982, 0.50459345, 0.58950016, 0.96776532, 0.37885727,\n",
       "       1.02108934, 0.45585733, 1.11807709, 1.16875204, 0.96599229,\n",
       "       1.14354595, 0.34339676, 0.42503079, 0.78585483, 1.07870751,\n",
       "       1.14044929, 0.58132547, 0.49572566, 0.78103088, 1.01504881,\n",
       "       1.11538667, 0.45087197, 1.17571509, 0.64800043, 0.36995203,\n",
       "       0.31665193, 0.74726421, 0.41196465, 0.99337951, 1.20388792,\n",
       "       0.69505611, 0.4753531 , 0.8826269 , 1.07491937, 0.41902918,\n",
       "       0.85739307, 1.19530607, 0.48325828, 0.31592756, 0.96420292,\n",
       "       0.55814139, 0.91509728, 0.86219796, 0.64568944, 0.35219445,\n",
       "       0.49237945, 0.80729456, 1.08995676, 0.97656351, 0.90901544,\n",
       "       0.75596308, 0.58233552, 0.75073305, 0.35289604])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2 = SVMClassifier()\n",
    "svm2.fit(Ones_Skin_X,Skin_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2.normalize_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00480062, -0.61446193, -0.61843088, -0.48985379])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924605295910747"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(Ones_Skin_X,Skin_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7924605295910747"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((Skin_Y-1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
       "        0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "        0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0., -2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat=np.random.random(Ones_Dota_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102944, 114)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ones_Dota_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
       "        0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ones_Dota_X[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ptron.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(svm2.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289, 0.90483289, 0.90483289,\n",
       "       0.90483289, 0.90483289, 0.90483289])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 3 - Occupancy Data from UCI ML repo\n",
    "Occupancy_Train = np.genfromtxt('datatraining.csv', delimiter = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8143, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Occupancy_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param list for KNN\n",
    "k_list = [1,2,3,4,5]\n",
    "knn_params = {\"k\" : k_list}\n",
    "\n",
    "#param list for perceptron\n",
    "epoch_list = [1,2,4,8,16]\n",
    "perceptron_params = {\"epochs\" : epoch_list}\n",
    "\n",
    "#param list for SVM\n",
    "lambda_list = [1,2,3,4,5]\n",
    "svm_params = {\"lambda\" : lambda_list}\n",
    "\n",
    "\n",
    "partition = [0.8, 0.5, 0.2]\n",
    "num_trials = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epoch_list:\n",
    "    for i in partition:\n",
    "        X_train = Ones_Skin_X[:-int(np.rint((1-i)*Ones_Skin_X.shape[0])),:] # Get features from train + val set.\n",
    "        X_test  = Ones_Skin_X[-int(np.rint((1-i)*Ones_Skin_X.shape[0])):,:] # Get features from test set.     \n",
    "        Y_train = Skin_Y[:-int(np.rint((1-i)*Skin_Y.shape[0]))] # Get labels from train + val set.\n",
    "        Y_test  = Skin_Y[-int(np.rint((1-i)*Skin_Y.shape[0])):] # Get labels from test set.  \n",
    "        for j in range(num_trials):\n",
    "            filename = \"./Perceptron/Skin/Perceptron_Skin_{}_epochs_{}{:1.1f}_trial_{}.txt\".format(epoch,i,1-i,j+1)\n",
    "            ptron = Perceptron(epochs = epoch)\n",
    "            ptron.fit(X_train,Y_train)\n",
    "            f= open(filename,\"w+\")\n",
    "            f.write(\"epochs = {}\\nw = {}\\ntraining accuracy is = {}\\ntesting accuracy is {}\".format(ptron.epochs, ptron.w,ptron.score(ptron.X_train, ptron.Y_train), ptron.score(X_test,Y_test)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epoch_list:\n",
    "    for i in partition:\n",
    "        X_train = Ones_Dota_X[:-int(np.rint((1-i)*Ones_Dota_X.shape[0])),:] # Get features from train + val set.\n",
    "        X_test  = Ones_Dota_X[-int(np.rint((1-i)*Ones_Dota_X.shape[0])):,:] # Get features from test set.     \n",
    "        Y_train = Dota_Y[:-int(np.rint((1-i)*Dota_Y.shape[0]))] # Get labels from train + val set.\n",
    "        Y_test  = Dota_Y[-int(np.rint((1-i)*Dota_Y.shape[0])):] # Get labels from test set.  \n",
    "        for j in range(num_trials):\n",
    "            filename = \"./Perceptron/Dota/Perceptron_Dota_{}_epochs_{}{:1.1f}_trial_{}.txt\".format(epoch,i,1-i,j+1)\n",
    "            ptron = Perceptron(epochs = epoch)\n",
    "            ptron.fit(X_train,Y_train)\n",
    "            f= open(filename,\"w+\")\n",
    "            f.write(\"epochs = {}\\nw = {}\\ntraining accuracy is = {}\\ntesting accuracy is {}\".format(ptron.epochs, ptron.w,ptron.score(ptron.X_train, ptron.Y_train), ptron.score(X_test,Y_test)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lmda in lmda_list:\n",
    "    for i in partition:\n",
    "        X_train = Ones_Skin_X[:-int(np.rint((1-i)*Ones_Skin_X.shape[0])),:] # Get features from train + val set.\n",
    "        X_test  = Ones_Skin_X[-int(np.rint((1-i)*Ones_Skin_X.shape[0])):,:] # Get features from test set.     \n",
    "        Y_train = Skin_Y[:-int(np.rint((1-i)*Skin_Y.shape[0]))] # Get labels from train + val set.\n",
    "        Y_test  = Skin_Y[-int(np.rint((1-i)*Skin_Y.shape[0])):] # Get labels from test set.  \n",
    "        for j in range(num_trials):\n",
    "            filename = \"./SVM/Skin/SVM_Skin_{}_lambda_{}{:1.1f}_trial_{}.txt\".format(lmda,i,1-i,j+1)\n",
    "            svm = SVMClassifier(lmda = lmda)\n",
    "            svm.fit(X_train,Y_train)\n",
    "            f= open(filename,\"w+\")\n",
    "            f.write(\"epochs = {}\\nw = {}\\ntraining accuracy is = {}\\ntesting accuracy is {}\".format(svm.epochs, svm.w,svm.score(ptron.X_train, ptron.Y_train), svm.score(X_test,Y_test)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lmda in lmda_list:\n",
    "    for i in partition:\n",
    "        X_train = Ones_Dota_X[:-int(np.rint((1-i)*Ones_Dota_X.shape[0])),:] # Get features from train + val set.\n",
    "        X_test  = Ones_Dota_X[-int(np.rint((1-i)*Ones_Dota_X.shape[0])):,:] # Get features from test set.     \n",
    "        Y_train = Dota_Y[:-int(np.rint((1-i)*Dota_Y.shape[0]))] # Get labels from train + val set.\n",
    "        Y_test  = Dota_Y[-int(np.rint((1-i)*Dota_Y.shape[0])):] # Get labels from test set.  \n",
    "        for j in range(num_trials):\n",
    "            filename = \"./SVM/Dota/SVM_Dota_{}_lambda_{}{:1.1f}_trial_{}.txt\".format(lmda,i,1-i,j+1)\n",
    "            svm = SVMClassifier(lmda = lmda)\n",
    "            svm.fit(X_train,Y_train)\n",
    "            f= open(filename,\"w+\")\n",
    "            f.write(\"epochs = {}\\nw = {}\\ntraining accuracy is = {}\\ntesting accuracy is {}\".format(svm.epochs, svm.w,svm.score(ptron.X_train, ptron.Y_train), svm.score(X_test,Y_test)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.476278364936276"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048328935585462"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.theta_star[81]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at Highest Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyparam['someParam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
